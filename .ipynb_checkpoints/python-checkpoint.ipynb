{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,  mutual_info_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from scipy.stats import uniform\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "\n",
    "#Descobrir quais variáveis \n",
    "X=pd.read_csv(\"train.csv\")\n",
    "y=X[\"TARGET\"]\n",
    "X_treino, X_teste, y_treino, y_teste=train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n",
    "X_treino=X_treino.drop([\"TARGET\",\"ID\"],axis=1)\n",
    "X_teste=X_teste.drop([\"TARGET\",\"ID\"],axis=1)\n",
    "remove = []\n",
    "for col in X_treino.columns:\n",
    "    if np.std(X_treino[col]) == 0:\n",
    "        remove.append(col)\n",
    "len(remove)\n",
    "\n",
    "X_treino.drop(remove, axis=1, inplace=True)\n",
    "X_teste.drop(remove, axis=1, inplace=True)\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "cols = X_treino.columns\n",
    "for i in range(len(cols)-1):\n",
    "    v = X_treino[cols[i]].values\n",
    "    for j in range(i+1,len(cols)):\n",
    "        if np.array_equal(v,X_treino[cols[j]].values):\n",
    "            remove.append(cols[j])\n",
    "len(remove)\n",
    "X_treino.drop(remove, axis=1, inplace=True)\n",
    "X_teste.drop(remove, axis=1, inplace=True)\n",
    "#Exportação para análise descritiva e criação de variáveis no R\n",
    "X_treino.to_csv(\"x_treino.csv\", index=False)\n",
    "X_teste.to_csv(\"x_teste.csv\", index=False)\n",
    "y_treino.to_csv(\"y_treino.csv\", index=False)\n",
    "y_teste.to_csv(\"y_teste.csv\", index=False)\n",
    "\n",
    "\n",
    "modelo_adaboost1=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7))\n",
    "modelo_adaboost1.fit(X_treino,y_treino)\n",
    "modelo_adaboost2=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4))\n",
    "modelo_adaboost2.fit(X_treino,y_treino)\n",
    "modelo_adaboost3=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2))\n",
    "modelo_adaboost3.fit(X_treino,y_treino)\n",
    "\n",
    "\n",
    "feat_imp1 = pd.Series(modelo_adaboost1.feature_importances_, index = X_treino.columns.values).sort_values(ascending=False)\n",
    "feat_imp1.iloc[:6]\n",
    "feat_imp2 = pd.Series(modelo_adaboost2.feature_importances_, index = X_treino.columns.values).sort_values(ascending=False)\n",
    "feat_imp2.iloc[:6]\n",
    "feat_imp3 = pd.Series(modelo_adaboost3.feature_importances_, index = X_treino.columns.values).sort_values(ascending=False)\n",
    "feat_imp3.iloc[:6]\n",
    "\n",
    "\n",
    "#Importação de dados após a criação de variável possivelmente relevcantes\n",
    "treino=pd.read_csv(\"treino_com_criacao_variaveis.csv\")\n",
    "teste=pd.read_csv(\"teste_com_criacao_variaveis.csv\")\n",
    "X=treino.drop([\"TARGET\"],axis=1)\n",
    "y=treino[\"TARGET\"]\n",
    "np.unique(y,return_counts=True)\n",
    "reamostragem=NearMiss(version=1, sampling_strategy={0:50000, 1:2406})\n",
    "X, y = reamostragem.fit_resample(X, y)\n",
    "#Seleção de variáveis\n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=61)\n",
    "X_2=selector.fit_transform(X,y)\n",
    "y_2=y.values\n",
    "\n",
    "k_vs_roc_teste = []\n",
    "k_vs_recall_0_teste = []\n",
    "k_vs_recall_1_teste = []\n",
    "k_vs_precision_0_teste = []\n",
    "k_vs_precision_1_teste = []\n",
    "k_vs_f1_1_teste = []\n",
    "k_vs_f1_0_teste = []\n",
    "k_vs_f1_teste = []\n",
    "\n",
    "k_vs_roc_treino = []\n",
    "k_vs_recall_0_treino = []\n",
    "k_vs_recall_1_treino = []\n",
    "k_vs_precision_0_treino = []\n",
    "k_vs_precision_1_treino = []\n",
    "k_vs_f1_1_treino = []\n",
    "k_vs_f1_0_treino = []\n",
    "k_vs_f1_treino = []\n",
    "indice_i=[]\n",
    "\n",
    "k=RepeatedStratifiedKFold(n_splits=3,n_repeats=1, random_state=7)\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for i in range(1,62,3):\n",
    "    recall_0_teste=[]\n",
    "    recall_1_teste=[]\n",
    "    precision_0_teste=[]\n",
    "    precision_1_teste=[]\n",
    "    roc_auc_teste=[]\n",
    "    f1_0_teste=[]\n",
    "    f1_1_teste=[]\n",
    "    f1_teste=[]\n",
    "    \n",
    "    recall_0_treino=[]\n",
    "    recall_1_treino=[]\n",
    "    precision_0_treino=[]\n",
    "    precision_1_treino=[]\n",
    "    roc_auc_treino=[]\n",
    "    f1_0_treino=[]\n",
    "    f1_1_treino=[]\n",
    "    f1_treino=[]\n",
    "    print(i)\n",
    "    for treino_index, teste_index in k.split(X_2,y_2):       \n",
    "        X_treino=X_2[treino_index,:] \n",
    "        X_teste=X_2[teste_index,:]\n",
    "        y_treino= y_2[treino_index] \n",
    "        y_teste=y_2[teste_index]\n",
    "        selector = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "        X_treino2=selector.fit_transform(X_treino,y_treino)\n",
    "        X_teste2=selector.transform(X_teste)\n",
    "        print(\"Passou a selecao a variaveis\")\n",
    "           \n",
    "        mdl = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4\n",
    "                        ,class_weight={0:1,1:20}),n_estimators=150)\n",
    "        mdl.fit(X_treino2, y_treino)\n",
    "        \n",
    "        y_prob_predict = mdl.predict_proba(X_teste2)[:,1]\n",
    "        y_predict_teste = mdl.predict(X_teste2)\n",
    "        y_predict_treino = mdl.predict(X_treino2)\n",
    "        \n",
    "        recall_0_teste.append(recall_score(y_teste, y_predict_teste, pos_label=0))\n",
    "        recall_1_teste.append(recall_score(y_teste, y_predict_teste, pos_label=1))\n",
    "        precision_0_teste.append(precision_score(y_teste, y_predict_teste, pos_label=0))\n",
    "        precision_1_teste.append(precision_score(y_teste, y_predict_teste, pos_label=1))\n",
    "        roc_auc_teste.append(roc_auc_score(y_teste, y_prob_predict))\n",
    "        f1_0_teste.append(f1_score(y_teste, y_predict_teste, pos_label=0))\n",
    "        f1_1_teste.append(f1_score(y_teste, y_predict_teste, pos_label=1))\n",
    "        f1_teste.append(f1_score(y_teste, y_predict_teste, average=\"macro\"))\n",
    "        \n",
    "        recall_0_treino.append(recall_score(y_treino, y_predict_treino, pos_label=0))\n",
    "        recall_1_treino.append(recall_score(y_treino, y_predict_treino, pos_label=1))\n",
    "        precision_0_treino.append(precision_score(y_treino, y_predict_treino, pos_label=0))\n",
    "        precision_1_treino.append(precision_score(y_treino, y_predict_treino, pos_label=1))\n",
    "        roc_auc_treino.append(roc_auc_score(y_treino, mdl.predict_proba(X_treino2)[:,1]))\n",
    "        f1_0_treino.append(f1_score(y_treino, y_predict_treino, pos_label=0))\n",
    "        f1_1_treino.append(f1_score(y_treino, y_predict_treino, pos_label=1))\n",
    "        f1_treino.append(f1_score(y_treino, y_predict_treino, average=\"macro\"))\n",
    "        \n",
    "    k_vs_roc_treino.append(np.mean(roc_auc_treino))\n",
    "    k_vs_recall_0_treino.append(np.mean(recall_0_treino))\n",
    "    k_vs_recall_1_treino.append(np.mean(recall_1_treino))\n",
    "    k_vs_precision_0_treino.append(np.mean(precision_0_treino))\n",
    "    k_vs_precision_1_treino.append(np.mean(precision_1_treino))\n",
    "    k_vs_f1_0_treino.append(np.mean(f1_0_treino))\n",
    "    k_vs_f1_1_treino.append(np.mean(f1_1_treino))\n",
    "    k_vs_f1_treino.append(np.mean(f1_treino))\n",
    "    \n",
    "    k_vs_roc_teste.append(np.mean(roc_auc_teste))\n",
    "    k_vs_recall_0_teste.append(np.mean(recall_0_teste))\n",
    "    k_vs_recall_1_teste.append(np.mean(recall_1_teste))\n",
    "    k_vs_precision_0_teste.append(np.mean(precision_0_teste))\n",
    "    k_vs_precision_1_teste.append(np.mean(precision_1_teste))\n",
    "    k_vs_f1_0_teste.append(np.mean(f1_0_teste))\n",
    "    k_vs_f1_1_teste.append(np.mean(f1_1_teste))\n",
    "    k_vs_f1_teste.append(np.mean(f1_teste))\n",
    "       \n",
    "    indice_i.append(i)\n",
    "\n",
    "    print(\"Roc AUC treino: {} - Roc AUC teste: {}\".format(np.mean(roc_auc_treino), np.mean(roc_auc_teste) ))\n",
    "    print(\"Recall classe 0 treino: {} - Recall classe 0 teste: {}\".format(np.mean(recall_0_treino), np.mean(recall_0_teste) ))\n",
    "    print(\"Recall classe 1 treino: {} - Recall classe 1 teste: {}\".format(np.mean(recall_1_treino), np.mean(recall_1_teste) ))\n",
    "    print(\"Precision classe 0 treino: {} - Precision classe 0 teste: {}\".format(np.mean(precision_0_treino), np.mean(precision_0_teste) ))\n",
    "    print(\"Precision classe 1 treino: {} - Precision classe 1 teste: {}\".format(np.mean(precision_1_treino), np.mean(precision_1_teste) ))\n",
    "    print(\"F1 classe 0 treino: {} - F1 classe 0 teste: {}\".format(np.mean(f1_0_treino), np.mean(f1_0_teste) ))\n",
    "    print(\"F1 classe 1 treino: {} - F1 classe 1 teste: {}\".format(np.mean(f1_1_treino), np.mean(f1_1_teste) ))\n",
    "    print(\"F1 Geral treino: {} - F1 Geral teste: {}\".format(np.mean(f1_treino), np.mean(f1_teste) ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "metricas=pd.DataFrame({\"indices\":indice_i,\"roc_auc_treino\":k_vs_roc_treino,\n",
    "\"roc_auc_teste\":k_vs_roc_teste, \"recall_0_treino\": k_vs_recall_0_treino,\n",
    "\"recall_0_teste\":k_vs_recall_0_teste, \"recall_1_treino\": k_vs_recall_1_treino,\n",
    "\"recall_1_teste\": k_vs_recall_1_teste, \"precision_0_treino\": k_vs_precision_0_treino,\n",
    "\"precision_0_teste\": k_vs_precision_0_teste, \"precision_1_treino\": k_vs_precision_1_treino,\n",
    "\"precision_1_teste\": k_vs_precision_1_teste, \"f1_0_treino\":k_vs_f1_0_treino,\n",
    "\"f1_0_teste\": k_vs_f1_0_teste, \"f1_1_treino\": k_vs_f1_1_treino,\n",
    "\"f1_1_teste\": k_vs_f1_1_teste, \"f1_treino\": k_vs_f1_treino,\n",
    "\"f1_teste\": k_vs_f1_teste})\n",
    "\n",
    "metricas.to_csv(path_or_buf=\"\\\\Users\\\\Alberto\\\\Desktop\\\\ime-usp\\\\aprendizagem_estatistica\\\\trabalho_aplicacao\\\\metricas.csv\", index=False)\n",
    "\n",
    "#Quantidade variáveis escolhidas pro enquanto: 31, escolhido pelas métricas\n",
    "#de recall, precision e f1 Score\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=31)\n",
    "selector.fit(X,y)\n",
    "#selector.get_support()\n",
    "#Variáveis selecionadas\n",
    "X.loc[:,selector.get_support()].columns\n",
    "X_2=selector.transform(X)\n",
    "y_2=y.values\n",
    "\n",
    "#pd.DataFrame(X_2,columns=X.loc[:,selector.get_support()].columns)\n",
    "#Modelagem preditiva\n",
    "#,Análise discriminante linear,Análise discriminante quadrático\n",
    "modelo1=LinearDiscriminantAnalysis()\n",
    "modelo2=QuadraticDiscriminantAnalysis()\n",
    "\n",
    "erro1,erro2=([],[])\n",
    "cont=0\n",
    "for treino_index, teste_index in k.split(X_2,y_2):\n",
    "    cont=cont+1\n",
    "    print(cont)\n",
    "    xtreino=X_2[treino_index,:] \n",
    "    xteste=X_2[teste_index,:]\n",
    "    ytreino= y_2[treino_index] \n",
    "    yteste=y_2[teste_index]\n",
    "    \n",
    "    modelo1.fit(xtreino,ytreino)\n",
    "    modelo2.fit(xtreino,ytreino)\n",
    "  \n",
    "    f1_modelo1 = recall_score(yteste, modelo1.predict(xteste), pos_label=1)\n",
    "    f1_modelo2 = recall_score(yteste, modelo2.predict(xteste), pos_label=1)\n",
    "\n",
    "    erro1.append(f1_modelo1)\n",
    "    erro2.append(f1_modelo2)\n",
    "  \n",
    "print(np.mean(erro1))\n",
    "print(np.mean(erro2))\n",
    "tabela_media=[np.mean(erro1),np.mean(erro2)]\n",
    "desvio=[np.std(erro1),np.std(erro2)]\n",
    "hiper_parametros=[\"Nenhum\",\"Nenhum\"]\n",
    "\n",
    "\n",
    "#Floresta Aleatória\n",
    "modelo=RandomForestClassifier(n_estimators=150)\n",
    "hiperp = {\"max_depth\":[1,2,3,4,5],\n",
    "\"min_samples_split\":[5,10,30,50],\"min_samples_leaf\":[5,10,15,25,30],\n",
    "\"class_weight\":[\"balanced\", {0:1,1:10},{0:1,1:20}]}\n",
    "Otimizacao = RandomizedSearchCV(modelo, hiperp,cv=k, n_iter = 20\n",
    "                    ,scoring=\"recall\", random_state=0)\n",
    "Otimizacao.fit(X_2, y_2)\n",
    "Otimizacao.cv_results_\n",
    "Otimizacao.best_params_\n",
    "erro=Otimizacao.best_score_\n",
    "tabela_media.append(erro)\n",
    "ind_menor_erro=np.argsort(Otimizacao.cv_results_[\"mean_test_score\"])[-1]\n",
    "dp=Otimizacao.cv_results_[\"std_test_score\"][ind_menor_erro]\n",
    "desvio.append(dp)\n",
    "hiper_parametros.append(Otimizacao.best_params_)\n",
    "print(\"Random Forest finalizado!\")\n",
    "\n",
    "\n",
    "#AdaBoost\n",
    "modelo=AdaBoostClassifier(n_estimators=200)\n",
    "hiperp = { \"base_estimator\":[\n",
    "    DecisionTreeClassifier(max_depth=3,class_weight={0:1,1:10}),\n",
    "    DecisionTreeClassifier(max_depth=3,class_weight={0:1,1:20}),\n",
    "    DecisionTreeClassifier(max_depth=3,class_weight=\"balanced\"),\n",
    "    DecisionTreeClassifier(max_depth=5,class_weight={0:1,1:10}),\n",
    "    DecisionTreeClassifier(max_depth=5,class_weight={0:1,1:20}),\n",
    "    DecisionTreeClassifier(max_depth=5,class_weight=\"balanced\")]}\n",
    "Otimizacao = GridSearchCV(modelo, hiperp,cv=k, scoring=\"recall\")\n",
    "Otimizacao.fit(X_2, y_2)\n",
    "Otimizacao.cv_results_\n",
    "Otimizacao.best_params_\n",
    "erro=Otimizacao.best_score_\n",
    "tabela_media.append(erro)\n",
    "ind_menor_erro=np.argsort(Otimizacao.cv_results_[\"mean_test_score\"])[-1]\n",
    "dp=Otimizacao.cv_results_[\"std_test_score\"][ind_menor_erro]\n",
    "desvio.append(dp)\n",
    "hiper_parametros.append(Otimizacao.best_params_)\n",
    "print(\"AdaBoost finalizado!\")\n",
    "\n",
    "#GradientBoosting\n",
    "modelo=GradientBoostingClassifier(n_estimators=200)\n",
    "hiperp = { \"max_depth\":[3, 5, 7]}\n",
    "Otimizacao = GridSearchCV(modelo, hiperp,cv=k, scoring=\"recall\")\n",
    "Otimizacao.fit(X_2, y_2)\n",
    "Otimizacao.cv_results_\n",
    "Otimizacao.best_params_\n",
    "erro=Otimizacao.best_score_\n",
    "tabela_media.append(erro)\n",
    "ind_menor_erro=np.argsort(Otimizacao.cv_results_[\"mean_test_score\"])[-1]\n",
    "dp=Otimizacao.cv_results_[\"std_test_score\"][ind_menor_erro]\n",
    "desvio.append(dp)\n",
    "hiper_parametros.append(Otimizacao.best_params_)\n",
    "print(\"Gradient Boosting finalizado!\")\n",
    "\n",
    "#Regressão Logística\n",
    "modelo=LogisticRegression(max_iter=500)\n",
    "hiperp = { \"class_weight\":[\"balanced\",{0:1,1:10}\n",
    ",{0:1,1:20}], \"C\":uniform(loc=0,scale=5)}\n",
    "Otimizacao = RandomizedSearchCV(modelo, hiperp,cv=k, n_iter = 20\n",
    "                    ,scoring=\"recall\", random_state=0)\n",
    "Otimizacao.fit(X_2, y_2)\n",
    "Otimizacao.cv_results_\n",
    "Otimizacao.best_params_\n",
    "erro=Otimizacao.best_score_\n",
    "tabela_media.append(erro)\n",
    "ind_menor_erro=np.argsort(Otimizacao.cv_results_[\"mean_test_score\"])[-1]\n",
    "dp=Otimizacao.cv_results_[\"std_test_score\"][ind_menor_erro]\n",
    "desvio.append(dp)\n",
    "hiper_parametros.append(Otimizacao.best_params_)\n",
    "print(\"Regressão Logística finalizada!\")\n",
    "\n",
    "tabela_media\n",
    "\n",
    "hiper_parametros[2].update({\"n_estimators\":150})\n",
    "hiper_parametros[3].update({\"n_estimators\":200})\n",
    "hiper_parametros[4].update({\"n_estimators\":20})\n",
    "hiper_parametros[5].update({\"max_iter\":500})\n",
    "\n",
    "X_teste=teste.drop([\"TARGET\"], axis=1)\n",
    "X_teste=selector.transform(X_teste)\n",
    "y_teste=teste[\"TARGET\"]\n",
    "\n",
    "X_teste.shape\n",
    "\n",
    "modelos=[LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis(), RandomForestClassifier(**hiper_parametros[2]), AdaBoostClassifier(**hiper_parametros[3]), GradientBoostingClassifier(**hiper_parametros[4]), LogisticRegression(**hiper_parametros[5])]\n",
    "#modelos=[LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis(), RandomForestClassifier(**hiper_parametros[2]), AdaBoostClassifier(**hiper_parametros[3]), GradientBoostingClassifier(**hiper_parametros[4]), LogisticRegression(**hiper_parametros[5])]\n",
    "for modelo in modelos:\n",
    "    print(\"Modelo: \", modelo)\n",
    "    modelo.fit(X_2,y_2)\n",
    "    y_predict=modelo.predict(X_teste)\n",
    "    \n",
    "    print(\"Recall classe 0: \", recall_score(y_teste, y_predict, pos_label=0))\n",
    "    print(\"Recall classe 1: \",recall_score(y_teste, y_predict, pos_label=1))\n",
    "    print(\"Precision classe 0: \", precision_score(y_teste, y_predict, pos_label=0))\n",
    "    print(\"Precision classe 1: \", precision_score(y_teste, y_predict, pos_label=1))\n",
    "    print(\"F1 classe 0: \", f1_score(y_teste, y_predict, pos_label=0))\n",
    "    print(\"F1 classe 1: \", f1_score(y_teste, y_predict, pos_label=1))\n",
    "    print(\"F1 Score Médio: \", f1_score(y_teste, y_predict, average=\"macro\"))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "##Vendo diferentes melhores para os modelos AdaBoost e GradientBoosting\n",
    "modelo1=AdaBoostClassifier(n_estimators=200, base_estimator= DecisionTreeClassifier(class_weight={0: 1, 1: 10}, max_depth=3))\n",
    "modelo2=GradientBoostingClassifier(n_estimators=200, max_depth= 7)\n",
    "\n",
    "f1_classe0_modelo1=[]\n",
    "f1_classe1_modelo1=[]\n",
    "recall_classe0_modelo1=[]\n",
    "recall_classe1_modelo1=[]\n",
    "precision_classe0_modelo1=[]\n",
    "precision_classe1_modelo1=[]\n",
    "f1_geral_modelo1=[]\n",
    "roc_auc_modelo1=[]\n",
    "\n",
    "f1_classe0_modelo2=[]\n",
    "f1_classe1_modelo2=[]\n",
    "recall_classe0_modelo2=[]\n",
    "recall_classe1_modelo2=[]\n",
    "precision_classe0_modelo2=[]\n",
    "precision_classe1_modelo2=[]\n",
    "f1_geral_modelo2=[]\n",
    "roc_auc_modelo2=[]\n",
    "cont=0\n",
    "\n",
    "for treino_index, teste_index in k.split(X_2,y_2):\n",
    "    cont=cont+1\n",
    "    \n",
    "    xtreino=X_2[treino_index,:] \n",
    "    xteste=X_2[teste_index,:]\n",
    "    ytreino= y_2[treino_index] \n",
    "    yteste=y_2[teste_index]\n",
    "    \n",
    "    modelo1.fit(xtreino,ytreino)\n",
    "  \n",
    "    prob_predict1 = modelo1.predict_proba(xteste)[:,1]\n",
    "    y_predict1 = modelo1.predict(xteste)\n",
    "    \n",
    "    recall_classe0_modelo1.append(recall_score(yteste, y_predict1, pos_label=0))\n",
    "    recall_classe1_modelo1.append(recall_score(yteste, y_predict1, pos_label=1))\n",
    "    precision_classe0_modelo1.append(precision_score(yteste, y_predict1, pos_label=0))\n",
    "    precision_classe1_modelo1.append(precision_score(yteste, y_predict1, pos_label=1))\n",
    "    roc_auc_modelo1.append(roc_auc_score(yteste, prob_predict1))\n",
    "    f1_classe0_modelo1.append(f1_score(yteste, y_predict1, pos_label=0))\n",
    "    f1_classe1_modelo1.append(f1_score(yteste, y_predict1, pos_label=1))\n",
    "    f1_geral_modelo1.append(f1_score(yteste, y_predict1, average=\"macro\"))\n",
    "        \n",
    "    modelo2.fit(xtreino,ytreino)\n",
    "    \n",
    "    prob_predict2 = modelo2.predict_proba(xteste)[:,1]\n",
    "    y_predict2 = modelo2.predict(xteste)\n",
    "    \n",
    "    recall_classe0_modelo2.append(recall_score(yteste, y_predict2, pos_label=0))\n",
    "    recall_classe1_modelo2.append(recall_score(yteste, y_predict2, pos_label=1))\n",
    "    precision_classe0_modelo2.append(precision_score(yteste, y_predict2, pos_label=0))\n",
    "    precision_classe1_modelo2.append(precision_score(yteste, y_predict2, pos_label=1))\n",
    "    roc_auc_modelo2.append(roc_auc_score(yteste, prob_predict2))\n",
    "    f1_classe0_modelo2.append(f1_score(yteste, y_predict2, pos_label=0))\n",
    "    f1_classe1_modelo2.append(f1_score(yteste, y_predict2, pos_label=1))\n",
    "    f1_geral_modelo2.append(f1_score(yteste, y_predict2, average=\"macro\"))\n",
    "    print(cont)\n",
    "\n",
    "np.mean(f1_classe0_modelo1)\n",
    "np.mean(f1_classe1_modelo1)\n",
    "np.mean(recall_classe0_modelo1)\n",
    "np.mean(recall_classe1_modelo1)\n",
    "np.mean(precision_classe0_modelo1)\n",
    "np.mean(precision_classe1_modelo1)\n",
    "np.mean(f1_geral_modelo1)\n",
    "np.mean(roc_auc_modelo1)\n",
    "\n",
    "np.mean(f1_classe0_modelo2)\n",
    "np.mean(f1_classe1_modelo2)\n",
    "np.mean(recall_classe0_modelo2)\n",
    "np.mean(recall_classe1_modelo2)\n",
    "np.mean(precision_classe0_modelo2)\n",
    "np.mean(precision_classe1_modelo2)\n",
    "np.mean(f1_geral_modelo2)\n",
    "np.mean(roc_auc_modelo2)\n",
    "\n",
    "metricas_boosting=pd.DataFrame({\"roc_auc_modelo1\":roc_auc_modelo1,\n",
    "\"roc_auc_modelo2\":roc_auc_modelo2, \"recall_0_modelo1\": recall_classe0_modelo1,\n",
    "\"recall_0_modelo2\":recall_classe0_modelo2, \"recall_1_modelo1\": recall_classe1_modelo1,\n",
    "\"recall_1_modelo2\": recall_classe1_modelo2, \"precision_0_modelo1\": precision_classe0_modelo1,\n",
    "\"precision_0_modelo2\": precision_classe0_modelo2, \"precision_1_modelo1\": precision_classe1_modelo1,\n",
    "\"precision_1_modelo2\": precision_classe1_modelo2, \"f1_0_modelo1\":f1_classe0_modelo1,\n",
    "\"f1_0_modelo2\": f1_classe0_modelo2, \"f1_1_modelo1\": f1_classe1_modelo1,\n",
    "\"f1_1_modelo2\": f1_classe1_modelo2, \"f1_modelo1\": f1_geral_modelo1,\n",
    "\"f1_modelo2\": f1_geral_modelo2})\n",
    "metricas_boosting.to_csv(path_or_buf=\"\\\\Users\\\\Alberto\\\\Desktop\\\\ime-usp\\\\aprendizagem_estatistica\\\\trabalho_aplicacao\\\\metricas_boosting.csv\", index=False)\n",
    "#Stacking\n",
    "\n",
    "cont=0\n",
    "erro_stacking=[]\n",
    "for treino_index, teste_index in k.split(X_2,y_2):\n",
    "    cont=cont+1\n",
    "    \n",
    "    xtreino=X_2[treino_index,:] \n",
    "    xteste=X_2[teste_index,:]\n",
    "    ytreino= y_2[treino_index] \n",
    "    yteste=y_2[teste_index]\n",
    "    \n",
    "    modelo1=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7,class_weight={0:1,1:10}), n_estimators=200)\n",
    "    modelo2=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7,class_weight={0:1,1:20}), n_estimators=200)\n",
    "    modelo3=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7,class_weight=\"balanced\"), n_estimators=200)\n",
    "    modelo4=GradientBoostingClassifier(n_estimators=200, max_depth=3)\n",
    "    modelo5=GradientBoostingClassifier(n_estimators=200, max_depth=5)\n",
    "    modelo6=GradientBoostingClassifier(n_estimators=200, max_depth=7)\n",
    "    modelo7=LogisticRegression()\n",
    "    #modelo8=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5,class_weight={0:1,1:20}), n_estimators=200)\n",
    "    #modelo9=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5,class_weight=\"balanced\"), n_estimators=200)\n",
    "\n",
    "    modelo1.fit(xtreino ,ytreino)\n",
    "    modelo2.fit(xtreino ,ytreino)\n",
    "    modelo3.fit(xtreino ,ytreino)\n",
    "    modelo4.fit(xtreino ,ytreino)\n",
    "    modelo5.fit(xtreino ,ytreino)\n",
    "    modelo6.fit(xtreino ,ytreino)\n",
    "    modelo7.fit(xtreino ,ytreino)\n",
    "    #modelo8.fit(xtreino ,ytreino)\n",
    "    #modelo9.fit(xtreino ,ytreino)\n",
    "    \n",
    "    probs1=modelo1.predict_proba(xtreino)\n",
    "    probs2=modelo2.predict_proba(xtreino)\n",
    "    probs3=modelo3.predict_proba(xtreino)\n",
    "    probs4=modelo4.predict_proba(xtreino)\n",
    "    probs5=modelo5.predict_proba(xtreino)\n",
    "    probs6=modelo6.predict_proba(xtreino)\n",
    "    probs7=modelo7.predict_proba(xtreino)\n",
    "    #probs8=modelo8.predict_proba(xtreino)\n",
    "    #probs9=modelo9.predict_proba(xtreino)\n",
    "    x_stacking=np.column_stack((probs1[:,1], probs2[:,1], probs3[:,1], probs4[:,1], probs5[:,1], probs6[:,1], probs7[:,1]))\n",
    "    modelo=LogisticRegression(class_weight= {0: 1, 1: 10})\n",
    "    #, class_weight= {0: 1, 1: 10}\n",
    "    modelo.fit(x_stacking, ytreino)\n",
    "    \n",
    "    probs1=modelo1.predict_proba(xteste)\n",
    "    probs2=modelo2.predict_proba(xteste)\n",
    "    probs3=modelo3.predict_proba(xteste)\n",
    "    probs4=modelo4.predict_proba(xteste)\n",
    "    probs5=modelo5.predict_proba(xteste)\n",
    "    probs6=modelo6.predict_proba(xteste)\n",
    "    probs7=modelo7.predict_proba(xteste)\n",
    "    #probs8=modelo8.predict_proba(xteste)\n",
    "    #probs9=modelo9.predict_proba(xteste)\n",
    "    x_teste_stacking=np.column_stack((probs1[:,1], probs2[:,1], probs3[:,1], probs4[:,1], probs5[:,1], probs6[:,1], probs7[:,1]))\n",
    "\n",
    "    f1_stacking = f1_score(yteste, modelo.predict(x_teste_stacking), pos_label=1)\n",
    "    erro_stacking.append(f1_stacking)\n",
    "    print(cont)\n",
    "\n",
    "np.mean(erro_stacking)    \n",
    "    \n",
    "#Submissao\n",
    "#Teste1: Melhor modelo AdaBoost com seleção de variáveis\n",
    "teste=pd.read_csv(\"teste_com_criacao_variaveis.csv\")\n",
    "teste_ID=teste[\"ID\"]\n",
    "teste2=teste.drop(\"ID\",axis=1)\n",
    "teste2.shape\n",
    "teste2=selector.transform(teste2)\n",
    "modelo=AdaBoostClassifier(**Otimizacao.best_params_)\n",
    "modelo.fit(X_2,y_2)\n",
    "probs=modelo.predict_proba(teste2)\n",
    "submission = pd.DataFrame({\"ID\":teste_ID, \"TARGET\": probs[:,1]})\n",
    "submission.to_csv(\"submission_melhor_modelo_adaboost.csv\", index=False)\n",
    "\n",
    "#Teste2: Stacking AdaBoost 3 modelos específicos\n",
    "\n",
    "hiperp = {\"class_weight\":[\"balanced\",{0:1,1:10}\n",
    ",{0:1,1:20}], \"C\":uniform(loc=0,scale=5)}\n",
    "Otimizacao = RandomizedSearchCV(modelo, hiperp,cv=k, n_iter = 10\n",
    "                    ,scoring=\"f1\", random_state=0)\n",
    "Otimizacao.fit(x_stacking, y_2)\n",
    "Otimizacao.cv_results_\n",
    "Otimizacao.best_params_\n",
    "Otimizacao.best_score_\n",
    "modelo=LogisticRegression(**Otimizacao.best_params_)\n",
    "\n",
    "\n",
    "teste=pd.read_csv(\"teste_com_criacao_variaveis.csv\")\n",
    "teste_ID=teste[\"ID\"]\n",
    "teste2=teste.drop(\"ID\",axis=1)\n",
    "teste2=selector.transform(teste2)\n",
    "probs1=modelo1.predict_proba(teste2)\n",
    "probs2=modelo2.predict_proba(teste2)\n",
    "probs3=modelo3.predict_proba(teste2)\n",
    "probs4=modelo4.predict_proba(teste2)\n",
    "probs5=modelo5.predict_proba(teste2)\n",
    "probs6=modelo6.predict_proba(teste2)\n",
    "#probs7=modelo7.predict_proba(teste2)\n",
    "#probs8=modelo8.predict_proba(teste2)\n",
    "#probs9=modelo9.predict_proba(teste2)\n",
    "x_teste_stacking=np.column_stack((probs1[:,1], probs2[:,1], probs3[:,1], probs4[:,1], probs5[:,1], probs6[:,1]))\n",
    "probs=modelo.predict_proba(x_teste_stacking)\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":teste_ID, \"TARGET\": probs[:,1]})\n",
    "submission.to_csv(\"submission_stacking2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
